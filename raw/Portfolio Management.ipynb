{"cells":[{"cell_type":"markdown","metadata":{"id":"TeWeixBt68Qt"},"source":["## Libraries used\n","This demonstration uses scipy for its non-linear solver.  For machine learning components, it uses torch, gymnasium, and stable-baselines3.  Additional libraries may be imported to assist with evaluation or presentation of results."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WLXwqRGc68Qv"},"outputs":[],"source":["import numpy as np\n","from scipy.optimize import minimize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xlObZg2h68Qw"},"outputs":[],"source":["import gymnasium as gym\n","from gymnasium import spaces"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TxB7qF-O68Qw"},"outputs":[],"source":["import torch as th"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFT5cJd968Qw"},"outputs":[],"source":["from stable_baselines3.ppo.policies import MlpPolicy\n","from stable_baselines3.common.vec_env import DummyVecEnv\n","from stable_baselines3 import PPO\n","from stable_baselines3.common.callbacks import EvalCallback"]},{"cell_type":"markdown","metadata":{"id":"aN9u3mSj68Qx"},"source":["## Data needed\n","In practice, one would likely use historical market data to build models.  This poses many challenges, as large and robust datasets are often currated by vendors.  Some free options are available, especially outside of commercial use.  However, to simplify things for this demonstration, we will simulate market data.\n","\n","Note that for machine learning applications using historical market data, there are often complexities related to how data is sampled.  If one is not careful, it is easy to overfit to limited historical data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sGnT8otS68Qx"},"outputs":[],"source":["def generate_market_params(assets, N, seed=None):\n","    if not seed is None:\n","        np.random.seed(seed)\n","\n","    uncorrelated_returns = np.random.normal(0.01,0.02,size=(N,assets))\n","    random_weights = np.random.normal(0,.3,size=(assets,assets))\n","    correlated_returns = uncorrelated_returns@random_weights\n","    mean_return = correlated_returns.mean(0)\n","    cov_return = np.cov(correlated_returns,rowvar=False)\n","    return mean_return, cov_return\n","\n","def generate_market_returns(mean,cov,N,seed=None):\n","    if not seed is None:\n","        np.random.seed(seed)\n","\n","    correlated_returns = np.random.multivariate_normal(mean,cov,N)\n","    return correlated_returns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n1HBqrNU68Qx"},"outputs":[],"source":["mu, Sig = generate_market_params(5,100)\n","simulated_returns = generate_market_returns(mu,Sig,100)"]},{"cell_type":"markdown","metadata":{"id":"YpXgEIbD68Qx"},"source":["## Traditional portfolio optimization\n","Traditionally, one would construct a portfolio by first defining the distribution of returns.  This generally requires an assumption for the distribution.  For simplicity, we will assume the assets follow a multivariate normal distribution.  Much research shows that fatter tails are common, and for some assets, a normal distribution wouldn't make sense - but thsi is just for exposition.  A multivariate normal distribution is described by two parameters, $\\mu$ and $\\Sigma$.  $\\mu$ is a vector of means for each of the random normals, and $\\Sigma$ is a matrix of their covariances.\n","\n","Once these parameters are set, then we can calculate various metrics, such as the expected return, the expected standard deviation, the sharpe ratio, the value-at-risk, etc.  We can use these metrics along with a solver, such as the solver in scipy, to minimize or maximize the metric's value over all feasible allocations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbPNzF7E68Qx"},"outputs":[],"source":["mu_est = simulated_returns.mean(0)\n","cov_est = np.cov(simulated_returns,rowvar=False)\n","\n","def expected_sharpe_ratio(x,mu,sigma,risk_free_rate=0):\n","    exp_return = x@mu\n","    std_dev = np.sqrt(x@sigma@x)\n","    return -(exp_return-risk_free_rate)/std_dev\n","\n","def canonical_optim(mu,sigma,risk_free_rate=0):\n","    constraints=[{'type':'eq','fun':lambda x: x.sum(0)-1}]\n","    rslt = minimize(fun=expected_sharpe_ratio\n","                   ,x0=[1,0,0,0,0]\n","                   ,constraints=constraints\n","                   ,args=(mu,sigma, risk_free_rate)\n","                   ,bounds=((0,1),(0,1),(0,1),(0,1),(0,1)))\n","    return rslt.x.round(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0T76VGxE68Qx","outputId":"c64a45bf-7d40-41dc-c4d8-598444eea1da"},"outputs":[{"data":{"text/plain":["array([0.  , 0.07, 0.  , 0.93, 0.  ])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["canonical_optim(mu_est,cov_est)"]},{"cell_type":"markdown","metadata":{"id":"dF_TXqDm68Qy"},"source":["## Skipping estimation of parameters\n","Instead of explicitly estimating the parameters of the distribution for the asset returns, we can calculate historical metrics directly.  This can help us avoid some of the pitfalls of bad assumptions for the distribution, but it doesn't allow us to add in expert judgement about the value of the parameters (e.g. if we think a certain asset classes will have higher performance in the future)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzTmTvRI68Qy"},"outputs":[],"source":["def historical_sharpe_ratio(x,returns,risk_free_rate=0):\n","    port_return = returns@x\n","    port_mean = port_return.mean()\n","    port_std_dev = port_return.std()\n","    return -(port_mean-risk_free_rate)/port_std_dev\n","\n","def data_optim(returns,risk_free_rate=0):\n","    constraints=[{'type':'eq','fun':lambda x: x.sum(0)-1}]\n","    rslt = minimize(fun=historical_sharpe_ratio\n","                   ,x0=[1,0,0,0,0]\n","                   ,constraints=constraints\n","                   ,args=(returns, risk_free_rate)\n","                   ,bounds=((0,1),(0,1),(0,1),(0,1),(0,1)))\n","    return rslt.x.round(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBrtjH0a68Qy","outputId":"66d3d2af-ca70-461a-aa3c-a87cefeb798f"},"outputs":[{"data":{"text/plain":["array([0.  , 0.07, 0.  , 0.93, 0.  ])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["data_optim(simulated_returns)"]},{"cell_type":"markdown","metadata":{"id":"GCKJ-z7c68Qy"},"source":["## Very simple application of reinforcement learning\n","Another approach to finding an optimal asset allocation is to use reinforcement learning.\n","\n","To start, let's think about the problem the same way we thought about it in the traditional setting - we want to maximize the historical sharpe ratio by selecting the best asset allocation.  To do this, we set the reward as the sharpe ratio and try and find the policy that will maximize it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aw82q9dc68Qz"},"outputs":[],"source":["class InvestmentGame0(gym.Env):\n","    def __init__(self,returns,risk_free_rate=0):\n","        super(InvestmentGame0,self).__init__()\n","        self.action_space = spaces.Box(\n","            low=0,high=1,shape=(5,),dtype=np.float32)\n","        self.observation_space=spaces.Box(\n","            low=-1, high=1, shape=(returns.shape),dtype=np.float32)\n","        self.reward_range=(-10,10)\n","        self.returns = returns\n","        self.risk_free_rate = risk_free_rate\n","\n","    def step(self,action):\n","        self.current_action = action\n","        if action.sum()==0:\n","            self.weights = (action+1)/5\n","        else:\n","            self.weights = action/action.sum()\n","\n","        port_returns = self.returns@self.weights\n","        sharpe = (port_returns.mean()-self.risk_free_rate)/port_returns.std()\n","        reward = sharpe.clip(-10,10)\n","        terminated = 1\n","        obs =self._get_obs()\n","        info = {\"data\":1}\n","        return obs,reward,terminated,0,info\n","    def reset(self,seed=None):\n","        if not seed is None:\n","            np.random.seed(seed)\n","        obs = self._get_obs()\n","        return obs, {'data':1}\n","    def _get_obs(self):\n","        obs = self.returns\n","        return obs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mB5Ugx1M68Qz","outputId":"cf3460ae-1899-47a3-87b7-2e1e5551f94a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cpu device\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\tlhee\\AppData\\Local\\Continuum\\anaconda3\\envs\\port_mgmt\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:484: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["------------------------------\n","| time/              |       |\n","|    fps             | 1190  |\n","|    iterations      | 1     |\n","|    time_elapsed    | 8     |\n","|    total_timesteps | 10000 |\n","------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 1117      |\n","|    iterations           | 2         |\n","|    time_elapsed         | 17        |\n","|    total_timesteps      | 20000     |\n","| train/                  |           |\n","|    approx_kl            | 0.8414378 |\n","|    clip_fraction        | 0.843     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -6.79     |\n","|    explained_variance   | 0         |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.106    |\n","|    n_updates            | 10        |\n","|    policy_gradient_loss | -0.142    |\n","|    std                  | 0.923     |\n","|    value_loss           | 0.089     |\n","---------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 1060       |\n","|    iterations           | 3          |\n","|    time_elapsed         | 28         |\n","|    total_timesteps      | 30000      |\n","| train/                  |            |\n","|    approx_kl            | 0.28949165 |\n","|    clip_fraction        | 0.792      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -6.02      |\n","|    explained_variance   | -1.19e-07  |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.0968    |\n","|    n_updates            | 20         |\n","|    policy_gradient_loss | -0.147     |\n","|    std                  | 0.817      |\n","|    value_loss           | 0.112      |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 1019       |\n","|    iterations           | 4          |\n","|    time_elapsed         | 39         |\n","|    total_timesteps      | 40000      |\n","| train/                  |            |\n","|    approx_kl            | 0.16562338 |\n","|    clip_fraction        | 0.749      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -5.43      |\n","|    explained_variance   | 0          |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.109     |\n","|    n_updates            | 30         |\n","|    policy_gradient_loss | -0.145     |\n","|    std                  | 0.732      |\n","|    value_loss           | 0.0953     |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 1005       |\n","|    iterations           | 5          |\n","|    time_elapsed         | 49         |\n","|    total_timesteps      | 50000      |\n","| train/                  |            |\n","|    approx_kl            | 0.11125128 |\n","|    clip_fraction        | 0.684      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -4.97      |\n","|    explained_variance   | -2.38e-07  |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.0945    |\n","|    n_updates            | 40         |\n","|    policy_gradient_loss | -0.129     |\n","|    std                  | 0.662      |\n","|    value_loss           | 0.0732     |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 999        |\n","|    iterations           | 6          |\n","|    time_elapsed         | 60         |\n","|    total_timesteps      | 60000      |\n","| train/                  |            |\n","|    approx_kl            | 0.06723272 |\n","|    clip_fraction        | 0.611      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -4.57      |\n","|    explained_variance   | 1.79e-07   |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.0869    |\n","|    n_updates            | 50         |\n","|    policy_gradient_loss | -0.11      |\n","|    std                  | 0.609      |\n","|    value_loss           | 0.0452     |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 976         |\n","|    iterations           | 7           |\n","|    time_elapsed         | 71          |\n","|    total_timesteps      | 70000       |\n","| train/                  |             |\n","|    approx_kl            | 0.053446136 |\n","|    clip_fraction        | 0.552       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -4.19       |\n","|    explained_variance   | 0           |\n","|    learning_rate        | 0.02        |\n","|    loss                 | -0.082      |\n","|    n_updates            | 60          |\n","|    policy_gradient_loss | -0.0911     |\n","|    std                  | 0.563       |\n","|    value_loss           | 0.0277      |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 971        |\n","|    iterations           | 8          |\n","|    time_elapsed         | 82         |\n","|    total_timesteps      | 80000      |\n","| train/                  |            |\n","|    approx_kl            | 0.04205669 |\n","|    clip_fraction        | 0.511      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -3.85      |\n","|    explained_variance   | 0          |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.0672    |\n","|    n_updates            | 70         |\n","|    policy_gradient_loss | -0.0768    |\n","|    std                  | 0.526      |\n","|    value_loss           | 0.0179     |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 960        |\n","|    iterations           | 9          |\n","|    time_elapsed         | 93         |\n","|    total_timesteps      | 90000      |\n","| train/                  |            |\n","|    approx_kl            | 0.03456249 |\n","|    clip_fraction        | 0.449      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -3.55      |\n","|    explained_variance   | 0          |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.0598    |\n","|    n_updates            | 80         |\n","|    policy_gradient_loss | -0.0621    |\n","|    std                  | 0.494      |\n","|    value_loss           | 0.00843    |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 953         |\n","|    iterations           | 10          |\n","|    time_elapsed         | 104         |\n","|    total_timesteps      | 100000      |\n","| train/                  |             |\n","|    approx_kl            | 0.029697265 |\n","|    clip_fraction        | 0.437       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -3.24       |\n","|    explained_variance   | 0           |\n","|    learning_rate        | 0.02        |\n","|    loss                 | -0.0485     |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.0483     |\n","|    std                  | 0.465       |\n","|    value_loss           | 0.00444     |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 947         |\n","|    iterations           | 11          |\n","|    time_elapsed         | 116         |\n","|    total_timesteps      | 110000      |\n","| train/                  |             |\n","|    approx_kl            | 0.022884335 |\n","|    clip_fraction        | 0.402       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.96       |\n","|    explained_variance   | -1.19e-07   |\n","|    learning_rate        | 0.02        |\n","|    loss                 | -0.04       |\n","|    n_updates            | 100         |\n","|    policy_gradient_loss | -0.0399     |\n","|    std                  | 0.44        |\n","|    value_loss           | 0.00264     |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 939         |\n","|    iterations           | 12          |\n","|    time_elapsed         | 127         |\n","|    total_timesteps      | 120000      |\n","| train/                  |             |\n","|    approx_kl            | 0.022001034 |\n","|    clip_fraction        | 0.362       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.7        |\n","|    explained_variance   | -1.19e-07   |\n","|    learning_rate        | 0.02        |\n","|    loss                 | -0.0295     |\n","|    n_updates            | 110         |\n","|    policy_gradient_loss | -0.0328     |\n","|    std                  | 0.418       |\n","|    value_loss           | 0.00176     |\n","-----------------------------------------\n"]},{"name":"stdout","output_type":"stream","text":["-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 935         |\n","|    iterations           | 13          |\n","|    time_elapsed         | 139         |\n","|    total_timesteps      | 130000      |\n","| train/                  |             |\n","|    approx_kl            | 0.023140555 |\n","|    clip_fraction        | 0.367       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.45       |\n","|    explained_variance   | 0           |\n","|    learning_rate        | 0.02        |\n","|    loss                 | -0.0291     |\n","|    n_updates            | 120         |\n","|    policy_gradient_loss | -0.0258     |\n","|    std                  | 0.399       |\n","|    value_loss           | 0.000854    |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 930         |\n","|    iterations           | 14          |\n","|    time_elapsed         | 150         |\n","|    total_timesteps      | 140000      |\n","| train/                  |             |\n","|    approx_kl            | 0.023541369 |\n","|    clip_fraction        | 0.395       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.22       |\n","|    explained_variance   | 1.19e-07    |\n","|    learning_rate        | 0.02        |\n","|    loss                 | -0.026      |\n","|    n_updates            | 130         |\n","|    policy_gradient_loss | -0.0204     |\n","|    std                  | 0.38        |\n","|    value_loss           | 0.000467    |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 926         |\n","|    iterations           | 15          |\n","|    time_elapsed         | 161         |\n","|    total_timesteps      | 150000      |\n","| train/                  |             |\n","|    approx_kl            | 0.024151487 |\n","|    clip_fraction        | 0.397       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.99       |\n","|    explained_variance   | 1.19e-07    |\n","|    learning_rate        | 0.02        |\n","|    loss                 | -0.0186     |\n","|    n_updates            | 140         |\n","|    policy_gradient_loss | -0.016      |\n","|    std                  | 0.363       |\n","|    value_loss           | 0.000317    |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 924         |\n","|    iterations           | 16          |\n","|    time_elapsed         | 173         |\n","|    total_timesteps      | 160000      |\n","| train/                  |             |\n","|    approx_kl            | 0.013478624 |\n","|    clip_fraction        | 0.396       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.77       |\n","|    explained_variance   | -1.19e-07   |\n","|    learning_rate        | 0.02        |\n","|    loss                 | -0.00959    |\n","|    n_updates            | 150         |\n","|    policy_gradient_loss | -0.0101     |\n","|    std                  | 0.348       |\n","|    value_loss           | 0.00018     |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 921        |\n","|    iterations           | 17         |\n","|    time_elapsed         | 184        |\n","|    total_timesteps      | 170000     |\n","| train/                  |            |\n","|    approx_kl            | 0.03352999 |\n","|    clip_fraction        | 0.446      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -1.55      |\n","|    explained_variance   | 1.19e-07   |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.0114    |\n","|    n_updates            | 160        |\n","|    policy_gradient_loss | -0.00868   |\n","|    std                  | 0.332      |\n","|    value_loss           | 3.27e-05   |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 918        |\n","|    iterations           | 18         |\n","|    time_elapsed         | 195        |\n","|    total_timesteps      | 180000     |\n","| train/                  |            |\n","|    approx_kl            | 0.49495596 |\n","|    clip_fraction        | 0.721      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -1.11      |\n","|    explained_variance   | 0          |\n","|    learning_rate        | 0.02       |\n","|    loss                 | 0.0161     |\n","|    n_updates            | 170        |\n","|    policy_gradient_loss | 0.0111     |\n","|    std                  | 0.311      |\n","|    value_loss           | 1.53e-05   |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 918        |\n","|    iterations           | 19         |\n","|    time_elapsed         | 206        |\n","|    total_timesteps      | 190000     |\n","| train/                  |            |\n","|    approx_kl            | 0.07602294 |\n","|    clip_fraction        | 0.587      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.922     |\n","|    explained_variance   | 0          |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.00513   |\n","|    n_updates            | 180        |\n","|    policy_gradient_loss | 0.000241   |\n","|    std                  | 0.293      |\n","|    value_loss           | 9.11e-05   |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 916         |\n","|    iterations           | 20          |\n","|    time_elapsed         | 218         |\n","|    total_timesteps      | 200000      |\n","| train/                  |             |\n","|    approx_kl            | 0.021247419 |\n","|    clip_fraction        | 0.549       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.797      |\n","|    explained_variance   | 1.79e-07    |\n","|    learning_rate        | 0.02        |\n","|    loss                 | 3.6e-12     |\n","|    n_updates            | 190         |\n","|    policy_gradient_loss | 0.000216    |\n","|    std                  | 0.29        |\n","|    value_loss           | 1.29e-07    |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 915        |\n","|    iterations           | 21         |\n","|    time_elapsed         | 229        |\n","|    total_timesteps      | 210000     |\n","| train/                  |            |\n","|    approx_kl            | 0.21482284 |\n","|    clip_fraction        | 0.826      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.414     |\n","|    explained_variance   | 5.96e-08   |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.00332   |\n","|    n_updates            | 200        |\n","|    policy_gradient_loss | 0.0882     |\n","|    std                  | 0.263      |\n","|    value_loss           | 9.23e-05   |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 914        |\n","|    iterations           | 22         |\n","|    time_elapsed         | 240        |\n","|    total_timesteps      | 220000     |\n","| train/                  |            |\n","|    approx_kl            | 0.12344974 |\n","|    clip_fraction        | 0.652      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.341     |\n","|    explained_variance   | -1.19e-07  |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.00508   |\n","|    n_updates            | 210        |\n","|    policy_gradient_loss | 0.00443    |\n","|    std                  | 0.268      |\n","|    value_loss           | 2.49e-07   |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 912        |\n","|    iterations           | 23         |\n","|    time_elapsed         | 252        |\n","|    total_timesteps      | 230000     |\n","| train/                  |            |\n","|    approx_kl            | 0.22724232 |\n","|    clip_fraction        | 0.706      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.416     |\n","|    explained_variance   | 1.79e-07   |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.0078    |\n","|    n_updates            | 220        |\n","|    policy_gradient_loss | 0.00908    |\n","|    std                  | 0.273      |\n","|    value_loss           | 9.14e-05   |\n","----------------------------------------\n"]},{"name":"stdout","output_type":"stream","text":["----------------------------------------\n","| time/                   |            |\n","|    fps                  | 912        |\n","|    iterations           | 24         |\n","|    time_elapsed         | 263        |\n","|    total_timesteps      | 240000     |\n","| train/                  |            |\n","|    approx_kl            | 0.08060528 |\n","|    clip_fraction        | 0.601      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.471     |\n","|    explained_variance   | 0          |\n","|    learning_rate        | 0.02       |\n","|    loss                 | 0.00144    |\n","|    n_updates            | 230        |\n","|    policy_gradient_loss | 0.0149     |\n","|    std                  | 0.269      |\n","|    value_loss           | 1.17e-06   |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 912        |\n","|    iterations           | 25         |\n","|    time_elapsed         | 274        |\n","|    total_timesteps      | 250000     |\n","| train/                  |            |\n","|    approx_kl            | 0.12260431 |\n","|    clip_fraction        | 0.567      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.559     |\n","|    explained_variance   | -1.19e-07  |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.00498   |\n","|    n_updates            | 240        |\n","|    policy_gradient_loss | 0.0111     |\n","|    std                  | 0.278      |\n","|    value_loss           | 6.69e-06   |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 911         |\n","|    iterations           | 26          |\n","|    time_elapsed         | 285         |\n","|    total_timesteps      | 260000      |\n","| train/                  |             |\n","|    approx_kl            | 0.122005105 |\n","|    clip_fraction        | 0.582       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.435      |\n","|    explained_variance   | -1.19e-07   |\n","|    learning_rate        | 0.02        |\n","|    loss                 | -0.0016     |\n","|    n_updates            | 250         |\n","|    policy_gradient_loss | 0.00757     |\n","|    std                  | 0.269       |\n","|    value_loss           | 2.97e-05    |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 910        |\n","|    iterations           | 27         |\n","|    time_elapsed         | 296        |\n","|    total_timesteps      | 270000     |\n","| train/                  |            |\n","|    approx_kl            | 0.13584131 |\n","|    clip_fraction        | 0.558      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.579     |\n","|    explained_variance   | -2.38e-07  |\n","|    learning_rate        | 0.02       |\n","|    loss                 | 0.00192    |\n","|    n_updates            | 260        |\n","|    policy_gradient_loss | 0.00539    |\n","|    std                  | 0.276      |\n","|    value_loss           | 3.34e-06   |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 909        |\n","|    iterations           | 28         |\n","|    time_elapsed         | 307        |\n","|    total_timesteps      | 280000     |\n","| train/                  |            |\n","|    approx_kl            | 0.03748355 |\n","|    clip_fraction        | 0.522      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.359     |\n","|    explained_variance   | 0          |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.00873   |\n","|    n_updates            | 270        |\n","|    policy_gradient_loss | -0.00696   |\n","|    std                  | 0.269      |\n","|    value_loss           | 4.32e-07   |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 907         |\n","|    iterations           | 29          |\n","|    time_elapsed         | 319         |\n","|    total_timesteps      | 290000      |\n","| train/                  |             |\n","|    approx_kl            | 0.056343365 |\n","|    clip_fraction        | 0.419       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.469      |\n","|    explained_variance   | 5.96e-08    |\n","|    learning_rate        | 0.02        |\n","|    loss                 | 0.026       |\n","|    n_updates            | 280         |\n","|    policy_gradient_loss | 0.000735    |\n","|    std                  | 0.273       |\n","|    value_loss           | 2.74e-06    |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 907        |\n","|    iterations           | 30         |\n","|    time_elapsed         | 330        |\n","|    total_timesteps      | 300000     |\n","| train/                  |            |\n","|    approx_kl            | 0.10950054 |\n","|    clip_fraction        | 0.563      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.249     |\n","|    explained_variance   | 5.96e-08   |\n","|    learning_rate        | 0.02       |\n","|    loss                 | 0.0104     |\n","|    n_updates            | 290        |\n","|    policy_gradient_loss | 0.000185   |\n","|    std                  | 0.267      |\n","|    value_loss           | 9.71e-05   |\n","----------------------------------------\n"]},{"data":{"text/plain":["<stable_baselines3.ppo.ppo.PPO at 0x225a298e290>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["env = DummyVecEnv([lambda: InvestmentGame0(simulated_returns)])\n","policy_kwargs = dict(activation_fn=th.nn.ReLU,\n","                    net_arch=[dict(pi=[128,64,32],vf=[128,64,32])])\n","model0 = PPO(MlpPolicy, env, learning_rate=0.02, batch_size=1000, gamma=1, n_steps=10000, policy_kwargs=policy_kwargs, verbose=1)\n","obs = env.reset()\n","model0.learn(total_timesteps=300000)"]},{"cell_type":"markdown","metadata":{"id":"e4bkwARM68Qz"},"source":["### Evaluating results\n","In addition to the many typical metrics provided for RL models, which are printed by stable-baselines3, we may want to evaluate our model based on the specific circumstances and objectives of our problem.\n","\n","As can be seen, below, the policy model is able to learn to allocate funds very similarly to the traditional optimization model.  This is encouraging!  It means that our environment and training alogrithm are not completely useless..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6IdKe7OA68Qz","outputId":"6e6a46ba-f894-4ab0-9686-f776d3677969"},"outputs":[{"data":{"text/plain":["array([0., 0., 0., 1., 0.], dtype=float32)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["def alloc_predict(returns,model):\n","    raw_alloc = model.predict(returns)[0]\n","    if raw_alloc.sum() == 0:\n","        alloc = (raw_alloc+1)/5\n","    else:\n","        alloc = raw_alloc/raw_alloc.sum()\n","    return alloc\n","\n","alloc_predict(simulated_returns,model0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uovyeMhP68Qz","outputId":"5dc8adaa-328b-4c8f-88a8-5c2f05235b2b"},"outputs":[{"data":{"text/plain":["array([0.  , 0.07, 0.  , 0.93, 0.  ])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["data_optim(simulated_returns)"]},{"cell_type":"markdown","metadata":{"id":"Y-BltMvF68Qz"},"source":["#### A different set of market data\n","Unfortunately, the policy is not able to find an optimal strategy given different market data.  It only saw a single set of data in its training, so this should be expected."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AWQ9qnka68Qz","outputId":"2302ff6a-9c2b-41a0-9cf7-101446001515"},"outputs":[{"data":{"text/plain":["array([0., 0., 0., 1., 0.], dtype=float32)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["mu2,Sig2 = generate_market_params(5,100)\n","simulated_returns2 = generate_market_returns(mu2,Sig2,100)\n","alloc_predict(simulated_returns2,model0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j6lCUckW68Qz","outputId":"200bad85-b37f-4c0a-db47-58f1285d4468"},"outputs":[{"data":{"text/plain":["array([0.  , 0.  , 0.  , 0.29, 0.71])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["data_optim(simulated_returns2)"]},{"cell_type":"markdown","metadata":{"id":"EK1M-q6K68Q0"},"source":["### Another strategy for testing our model\n","In this case, we can look across many different markets (i.e. simulate many different historical market datasets) and see how similar our policy models is to the traditional model.  In this case, a plausible benchmark is to just compare our model to an 'even split' across each asset (i.e. 20% allocation).  If our policy isn't better than the benchmark, we probably should be concerned - and this is obviously the case.  Of course, this relates to the limited data seen in training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AvjiEZfn68Q0","outputId":"d36df4d4-fa34-4483-eab2-4cddc7b86d12"},"outputs":[{"data":{"text/plain":["(1.1853248797530855, 0.4009954000000001)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["def test_model_variance(model,N=1000):\n","    variance = []\n","    benchmark = []\n","    for i in range(N):\n","        mu,Sig = generate_market_params(5,100)\n","        simulated_returns = generate_market_returns(mu,Sig,100)\n","        predict_alloc = alloc_predict(simulated_returns,model)\n","        optimal_alloc = data_optim(simulated_returns)\n","        variance.append(((predict_alloc-optimal_alloc)**2).sum())\n","        benchmark.append(((0.2-optimal_alloc)**2).sum())\n","    return variance,benchmark\n","\n","model_sq_dif, bchmk_sq_dif = test_model_variance(model0)\n","\n","np.mean(model_sq_dif), np.mean(bchmk_sq_dif)"]},{"cell_type":"markdown","metadata":{"id":"yUWJjFnP68Q0"},"source":["### Looking at the rewards\n","A final way to evaluate the model is to compare the reward against a benchmark - in our case, the benchmark is the traditional approach.  Of course, the results are quite similar - but, agian, our environment only has a single set of historical returns so this result is not terribly interesting."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"otqVLZRO68Q0","outputId":"b1b59cbf-61ec-4ab3-8092-b1ce0df60048"},"outputs":[{"data":{"text/plain":["(737.7586317272794, 750.7688671394142)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["def policy_tester(environment,policy_model,N=1000,simulated_returns=None):\n","    if simulated_returns is None:\n","        env = environment()\n","    else:\n","        env = environment(simulated_returns)\n","    obs,_ = env.reset()\n","    total_reward = 0\n","    for i in range(N):\n","        obs,reward,term,_,_ = env.step(policy_model.predict(obs)[0])\n","        total_reward += reward\n","        if term==1:\n","            obs,_ = env.reset()\n","    model_reward = total_reward\n","    total_reward = 0\n","    for i in range(N):\n","        obs,reward,term,_,_ = env.step(data_optim(env.returns))\n","        total_reward += reward\n","        if term==1:\n","            obs,_ = env.reset()\n","    benchmark_reward = total_reward\n","    total_reward = 0\n","    return model_reward,benchmark_reward\n","\n","policy_tester(InvestmentGame0,model0,simulated_returns=simulated_returns)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YyUew0s-68Q0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5DM7KG4i68Q0"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"IdSgR2jH68Q0"},"source":["## Reinforcement learning with changing markets\n","Instead of feeding in a single set of historical returns to our environment, we can instead simulate a new set of historical market returns each time we reset our environment.  In this way, we are now asking our policy model to look at an arbitrary historical dataset and find the optimal policy.  This is much more interesting - although it is still very much something our traditional approach would handle."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"znfcwkML68Q0"},"outputs":[],"source":["class InvestmentGame1(gym.Env):\n","    def __init__(self,risk_free_rate=0):\n","        super(InvestmentGame1,self).__init__()\n","        self.action_space = spaces.Box(\n","            low=0,high=1,shape=(5,),dtype=np.float32)\n","        self.observation_space=spaces.Box(\n","            low=-1, high=1, shape=(100,5),dtype=np.float32)\n","        self.reward_range=(-10,10)\n","\n","        self.mu,self.Sig = generate_market_params(5,100)\n","        self.returns = generate_market_returns(self.mu,self.Sig,100)\n","\n","        self.risk_free_rate = risk_free_rate\n","\n","    def step(self,action):\n","        self.current_action = action\n","        if action.sum()==0:\n","            self.weights = (action+1)/5\n","        else:\n","            self.weights = action/action.sum()\n","\n","        port_returns = self.returns@self.weights\n","        sharpe = (port_returns.mean()-self.risk_free_rate)/port_returns.std()\n","        reward = sharpe.clip(-10,10)\n","        terminated = 1\n","        obs =self._get_obs()\n","        info = {\"data\":1}\n","        return obs,reward,terminated,0,info\n","    def reset(self,seed=None):\n","        if not seed is None:\n","            np.random.seed(seed)\n","\n","        self.mu,self.Sig = generate_market_params(5,100)\n","        self.returns = generate_market_returns(self.mu,self.Sig,100)\n","\n","        obs = self._get_obs()\n","        return obs, {'data':1}\n","    def _get_obs(self):\n","        obs = self.returns\n","        return obs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SVOMpCXz68Q0","outputId":"74dda758-2e89-4c2d-bd17-f18a6bedb3cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cpu device\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\tlhee\\AppData\\Local\\Continuum\\anaconda3\\envs\\port_mgmt\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:484: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["------------------------------\n","| time/              |       |\n","|    fps             | 843   |\n","|    iterations      | 1     |\n","|    time_elapsed    | 11    |\n","|    total_timesteps | 10000 |\n","------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 780        |\n","|    iterations           | 2          |\n","|    time_elapsed         | 25         |\n","|    total_timesteps      | 20000      |\n","| train/                  |            |\n","|    approx_kl            | 0.33151644 |\n","|    clip_fraction        | 0.641      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -7         |\n","|    explained_variance   | 0.00269    |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.0977    |\n","|    n_updates            | 10         |\n","|    policy_gradient_loss | -0.108     |\n","|    std                  | 0.965      |\n","|    value_loss           | 0.143      |\n","----------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 739       |\n","|    iterations           | 3         |\n","|    time_elapsed         | 40        |\n","|    total_timesteps      | 30000     |\n","| train/                  |           |\n","|    approx_kl            | 0.2572733 |\n","|    clip_fraction        | 0.754     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -6.67     |\n","|    explained_variance   | -0.0844   |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.114    |\n","|    n_updates            | 20        |\n","|    policy_gradient_loss | -0.107    |\n","|    std                  | 0.913     |\n","|    value_loss           | 0.134     |\n","---------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 721        |\n","|    iterations           | 4          |\n","|    time_elapsed         | 55         |\n","|    total_timesteps      | 40000      |\n","| train/                  |            |\n","|    approx_kl            | 0.33185205 |\n","|    clip_fraction        | 0.772      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -6.34      |\n","|    explained_variance   | 0.0296     |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.12      |\n","|    n_updates            | 30         |\n","|    policy_gradient_loss | -0.102     |\n","|    std                  | 0.857      |\n","|    value_loss           | 0.0953     |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 711        |\n","|    iterations           | 5          |\n","|    time_elapsed         | 70         |\n","|    total_timesteps      | 50000      |\n","| train/                  |            |\n","|    approx_kl            | 0.39673182 |\n","|    clip_fraction        | 0.782      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -5.98      |\n","|    explained_variance   | 0.114      |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.129     |\n","|    n_updates            | 40         |\n","|    policy_gradient_loss | -0.0984    |\n","|    std                  | 0.805      |\n","|    value_loss           | 0.0726     |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 699        |\n","|    iterations           | 6          |\n","|    time_elapsed         | 85         |\n","|    total_timesteps      | 60000      |\n","| train/                  |            |\n","|    approx_kl            | 0.52338374 |\n","|    clip_fraction        | 0.786      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -5.66      |\n","|    explained_variance   | 0.203      |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.127     |\n","|    n_updates            | 50         |\n","|    policy_gradient_loss | -0.0908    |\n","|    std                  | 0.747      |\n","|    value_loss           | 0.0578     |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 698        |\n","|    iterations           | 7          |\n","|    time_elapsed         | 100        |\n","|    total_timesteps      | 70000      |\n","| train/                  |            |\n","|    approx_kl            | 0.63371426 |\n","|    clip_fraction        | 0.792      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -5.31      |\n","|    explained_variance   | 0.337      |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.123     |\n","|    n_updates            | 60         |\n","|    policy_gradient_loss | -0.0746    |\n","|    std                  | 0.702      |\n","|    value_loss           | 0.0462     |\n","----------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 694       |\n","|    iterations           | 8         |\n","|    time_elapsed         | 115       |\n","|    total_timesteps      | 80000     |\n","| train/                  |           |\n","|    approx_kl            | 0.7394724 |\n","|    clip_fraction        | 0.784     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -5.05     |\n","|    explained_variance   | 0.434     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.129    |\n","|    n_updates            | 70        |\n","|    policy_gradient_loss | -0.0789   |\n","|    std                  | 0.658     |\n","|    value_loss           | 0.0373    |\n","---------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 689       |\n","|    iterations           | 9         |\n","|    time_elapsed         | 130       |\n","|    total_timesteps      | 90000     |\n","| train/                  |           |\n","|    approx_kl            | 0.7782723 |\n","|    clip_fraction        | 0.789     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -4.73     |\n","|    explained_variance   | 0.517     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.125    |\n","|    n_updates            | 80        |\n","|    policy_gradient_loss | -0.0765   |\n","|    std                  | 0.618     |\n","|    value_loss           | 0.0325    |\n","---------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 680        |\n","|    iterations           | 10         |\n","|    time_elapsed         | 146        |\n","|    total_timesteps      | 100000     |\n","| train/                  |            |\n","|    approx_kl            | 0.81588984 |\n","|    clip_fraction        | 0.789      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -4.44      |\n","|    explained_variance   | 0.564      |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.121     |\n","|    n_updates            | 90         |\n","|    policy_gradient_loss | -0.0628    |\n","|    std                  | 0.585      |\n","|    value_loss           | 0.0297     |\n","----------------------------------------\n","--------------------------------------\n","| time/                   |          |\n","|    fps                  | 684      |\n","|    iterations           | 11       |\n","|    time_elapsed         | 160      |\n","|    total_timesteps      | 110000   |\n","| train/                  |          |\n","|    approx_kl            | 0.960956 |\n","|    clip_fraction        | 0.791    |\n","|    clip_range           | 0.2      |\n","|    entropy_loss         | -4.17    |\n","|    explained_variance   | 0.606    |\n","|    learning_rate        | 0.02     |\n","|    loss                 | -0.104   |\n","|    n_updates            | 100      |\n","|    policy_gradient_loss | -0.0581  |\n","|    std                  | 0.55     |\n","|    value_loss           | 0.0281   |\n","--------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 685       |\n","|    iterations           | 12        |\n","|    time_elapsed         | 175       |\n","|    total_timesteps      | 120000    |\n","| train/                  |           |\n","|    approx_kl            | 1.0707698 |\n","|    clip_fraction        | 0.805     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -3.9      |\n","|    explained_variance   | 0.625     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.112    |\n","|    n_updates            | 110       |\n","|    policy_gradient_loss | -0.0462   |\n","|    std                  | 0.519     |\n","|    value_loss           | 0.0264    |\n","---------------------------------------\n"]},{"name":"stdout","output_type":"stream","text":["---------------------------------------\n","| time/                   |           |\n","|    fps                  | 689       |\n","|    iterations           | 13        |\n","|    time_elapsed         | 188       |\n","|    total_timesteps      | 130000    |\n","| train/                  |           |\n","|    approx_kl            | 1.1037052 |\n","|    clip_fraction        | 0.801     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -3.62     |\n","|    explained_variance   | 0.647     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.115    |\n","|    n_updates            | 120       |\n","|    policy_gradient_loss | -0.0435   |\n","|    std                  | 0.495     |\n","|    value_loss           | 0.0252    |\n","---------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 694       |\n","|    iterations           | 14        |\n","|    time_elapsed         | 201       |\n","|    total_timesteps      | 140000    |\n","| train/                  |           |\n","|    approx_kl            | 1.2024329 |\n","|    clip_fraction        | 0.795     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -3.4      |\n","|    explained_variance   | 0.652     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.102    |\n","|    n_updates            | 130       |\n","|    policy_gradient_loss | -0.0582   |\n","|    std                  | 0.467     |\n","|    value_loss           | 0.0245    |\n","---------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 698       |\n","|    iterations           | 15        |\n","|    time_elapsed         | 214       |\n","|    total_timesteps      | 150000    |\n","| train/                  |           |\n","|    approx_kl            | 1.4562422 |\n","|    clip_fraction        | 0.81      |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -3.12     |\n","|    explained_variance   | 0.653     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.1      |\n","|    n_updates            | 140       |\n","|    policy_gradient_loss | -0.0338   |\n","|    std                  | 0.443     |\n","|    value_loss           | 0.0253    |\n","---------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 700       |\n","|    iterations           | 16        |\n","|    time_elapsed         | 228       |\n","|    total_timesteps      | 160000    |\n","| train/                  |           |\n","|    approx_kl            | 1.2521346 |\n","|    clip_fraction        | 0.809     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -2.86     |\n","|    explained_variance   | 0.665     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.104    |\n","|    n_updates            | 150       |\n","|    policy_gradient_loss | -0.038    |\n","|    std                  | 0.421     |\n","|    value_loss           | 0.0244    |\n","---------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 700       |\n","|    iterations           | 17        |\n","|    time_elapsed         | 242       |\n","|    total_timesteps      | 170000    |\n","| train/                  |           |\n","|    approx_kl            | 1.4486228 |\n","|    clip_fraction        | 0.82      |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -2.69     |\n","|    explained_variance   | 0.674     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.071    |\n","|    n_updates            | 160       |\n","|    policy_gradient_loss | -0.0212   |\n","|    std                  | 0.406     |\n","|    value_loss           | 0.0239    |\n","---------------------------------------\n","--------------------------------------\n","| time/                   |          |\n","|    fps                  | 702      |\n","|    iterations           | 18       |\n","|    time_elapsed         | 256      |\n","|    total_timesteps      | 180000   |\n","| train/                  |          |\n","|    approx_kl            | 1.400903 |\n","|    clip_fraction        | 0.818    |\n","|    clip_range           | 0.2      |\n","|    entropy_loss         | -2.5     |\n","|    explained_variance   | 0.669    |\n","|    learning_rate        | 0.02     |\n","|    loss                 | -0.094   |\n","|    n_updates            | 170      |\n","|    policy_gradient_loss | -0.0211  |\n","|    std                  | 0.39     |\n","|    value_loss           | 0.0243   |\n","--------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 704       |\n","|    iterations           | 19        |\n","|    time_elapsed         | 269       |\n","|    total_timesteps      | 190000    |\n","| train/                  |           |\n","|    approx_kl            | 1.2624204 |\n","|    clip_fraction        | 0.809     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -2.29     |\n","|    explained_variance   | 0.672     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.0766   |\n","|    n_updates            | 180       |\n","|    policy_gradient_loss | -0.0257   |\n","|    std                  | 0.371     |\n","|    value_loss           | 0.0241    |\n","---------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 707       |\n","|    iterations           | 20        |\n","|    time_elapsed         | 282       |\n","|    total_timesteps      | 200000    |\n","| train/                  |           |\n","|    approx_kl            | 1.5438296 |\n","|    clip_fraction        | 0.82      |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -2.11     |\n","|    explained_variance   | 0.683     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.0776   |\n","|    n_updates            | 190       |\n","|    policy_gradient_loss | -0.0243   |\n","|    std                  | 0.362     |\n","|    value_loss           | 0.0236    |\n","---------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 710       |\n","|    iterations           | 21        |\n","|    time_elapsed         | 295       |\n","|    total_timesteps      | 210000    |\n","| train/                  |           |\n","|    approx_kl            | 1.5603263 |\n","|    clip_fraction        | 0.832     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -2        |\n","|    explained_variance   | 0.674     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.0607   |\n","|    n_updates            | 200       |\n","|    policy_gradient_loss | 0.0136    |\n","|    std                  | 0.351     |\n","|    value_loss           | 0.0243    |\n","---------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 713       |\n","|    iterations           | 22        |\n","|    time_elapsed         | 308       |\n","|    total_timesteps      | 220000    |\n","| train/                  |           |\n","|    approx_kl            | 1.5985332 |\n","|    clip_fraction        | 0.837     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -1.81     |\n","|    explained_variance   | 0.687     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.0657   |\n","|    n_updates            | 210       |\n","|    policy_gradient_loss | 0.0122    |\n","|    std                  | 0.344     |\n","|    value_loss           | 0.0235    |\n","---------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 715       |\n","|    iterations           | 23        |\n","|    time_elapsed         | 321       |\n","|    total_timesteps      | 230000    |\n","| train/                  |           |\n","|    approx_kl            | 1.4664444 |\n","|    clip_fraction        | 0.824     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -1.72     |\n","|    explained_variance   | 0.695     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.0732   |\n","|    n_updates            | 220       |\n","|    policy_gradient_loss | -0.00579  |\n","|    std                  | 0.332     |\n","|    value_loss           | 0.0232    |\n","---------------------------------------\n"]},{"name":"stdout","output_type":"stream","text":["---------------------------------------\n","| time/                   |           |\n","|    fps                  | 717       |\n","|    iterations           | 24        |\n","|    time_elapsed         | 334       |\n","|    total_timesteps      | 240000    |\n","| train/                  |           |\n","|    approx_kl            | 1.6053839 |\n","|    clip_fraction        | 0.835     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -1.56     |\n","|    explained_variance   | 0.697     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.0588   |\n","|    n_updates            | 230       |\n","|    policy_gradient_loss | 0.0177    |\n","|    std                  | 0.323     |\n","|    value_loss           | 0.0231    |\n","---------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 719       |\n","|    iterations           | 25        |\n","|    time_elapsed         | 347       |\n","|    total_timesteps      | 250000    |\n","| train/                  |           |\n","|    approx_kl            | 1.5413517 |\n","|    clip_fraction        | 0.833     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -1.42     |\n","|    explained_variance   | 0.707     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.027    |\n","|    n_updates            | 240       |\n","|    policy_gradient_loss | 0.0149    |\n","|    std                  | 0.312     |\n","|    value_loss           | 0.0227    |\n","---------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 721       |\n","|    iterations           | 26        |\n","|    time_elapsed         | 360       |\n","|    total_timesteps      | 260000    |\n","| train/                  |           |\n","|    approx_kl            | 3.8886764 |\n","|    clip_fraction        | 0.861     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -1.34     |\n","|    explained_variance   | 0.692     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.0311   |\n","|    n_updates            | 250       |\n","|    policy_gradient_loss | 0.0541    |\n","|    std                  | 0.305     |\n","|    value_loss           | 0.0234    |\n","---------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 723       |\n","|    iterations           | 27        |\n","|    time_elapsed         | 373       |\n","|    total_timesteps      | 270000    |\n","| train/                  |           |\n","|    approx_kl            | 1.8238386 |\n","|    clip_fraction        | 0.845     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -1.23     |\n","|    explained_variance   | 0.689     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.0546   |\n","|    n_updates            | 260       |\n","|    policy_gradient_loss | 0.027     |\n","|    std                  | 0.297     |\n","|    value_loss           | 0.0228    |\n","---------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 724       |\n","|    iterations           | 28        |\n","|    time_elapsed         | 386       |\n","|    total_timesteps      | 280000    |\n","| train/                  |           |\n","|    approx_kl            | 2.0058699 |\n","|    clip_fraction        | 0.858     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -1.12     |\n","|    explained_variance   | 0.711     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.0337   |\n","|    n_updates            | 270       |\n","|    policy_gradient_loss | 0.0451    |\n","|    std                  | 0.294     |\n","|    value_loss           | 0.0219    |\n","---------------------------------------\n","--------------------------------------\n","| time/                   |          |\n","|    fps                  | 726      |\n","|    iterations           | 29       |\n","|    time_elapsed         | 399      |\n","|    total_timesteps      | 290000   |\n","| train/                  |          |\n","|    approx_kl            | 1.628669 |\n","|    clip_fraction        | 0.826    |\n","|    clip_range           | 0.2      |\n","|    entropy_loss         | -0.961   |\n","|    explained_variance   | 0.721    |\n","|    learning_rate        | 0.02     |\n","|    loss                 | -0.0432  |\n","|    n_updates            | 280      |\n","|    policy_gradient_loss | -0.00411 |\n","|    std                  | 0.287    |\n","|    value_loss           | 0.022    |\n","--------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 727       |\n","|    iterations           | 30        |\n","|    time_elapsed         | 412       |\n","|    total_timesteps      | 300000    |\n","| train/                  |           |\n","|    approx_kl            | 1.4807119 |\n","|    clip_fraction        | 0.82      |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -0.842    |\n","|    explained_variance   | 0.699     |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.0771   |\n","|    n_updates            | 290       |\n","|    policy_gradient_loss | -0.0128   |\n","|    std                  | 0.279     |\n","|    value_loss           | 0.0226    |\n","---------------------------------------\n"]},{"data":{"text/plain":["<stable_baselines3.ppo.ppo.PPO at 0x225a74075d0>"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["env = DummyVecEnv([lambda: InvestmentGame1()])\n","policy_kwargs = dict(activation_fn=th.nn.ReLU,\n","                    net_arch=[dict(pi=[128,64,32],vf=[128,64,32])])\n","model1 = PPO(MlpPolicy, env, learning_rate=0.02, batch_size=1000, gamma=1, n_steps=10000, policy_kwargs=policy_kwargs, verbose=1)\n","obs = env.reset()\n","model1.learn(total_timesteps=300000)"]},{"cell_type":"markdown","metadata":{"id":"ECnOoNnm68Q0"},"source":["### The model is at least better than an even split\n","It is not much better at matching the traditional model than simply providing an even split across classes, but it is better than our previous policy model!  Maybe the difference between the policy model and the traditional model are the result of the reinforcement learning model finding some secret solution?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"apMlB0vp68Q1","outputId":"f146eb8c-bb11-4cc7-87c1-f9d01309ab09"},"outputs":[{"data":{"text/plain":["(0.32153623244537766, 0.39182820000000007)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["model_sq_dif,bchmk_sq_dif = test_model_variance(model1)\n","np.mean(model_sq_dif),np.mean(bchmk_sq_dif)"]},{"cell_type":"markdown","metadata":{"id":"6C0WWD8-68Q1"},"source":["### Looking at the rewards again\n","The policy model is inferior to just using the traditional model.  This could be remedied by additional training, using a different model architecture, adjusting parameters in the PPO alogrithm, etc.  However, it does beg the question, why bother with all of this machinery."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7D3AT_Z568Q1","outputId":"01b24542-2dd8-4164-dfbf-0bb022a1978a"},"outputs":[{"data":{"text/plain":["(605.3167785297682, 748.8410838916747)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["policy_tester(InvestmentGame1,model1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lP3lDCX668Q1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4O86VA9h68Q1"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"siUe-mVy68Q1"},"source":["## A (more) realistic scenario\n","Unlike our previous example, we can set up a more complex market environment.  In this case, we will have a hidden market state - depending on the state of the market, there will be a different underlying data generating process (i.e. different $\\mu$ and $\\Sigma$.\n","\n","In addition, there is now a cost associated with changing an asset allocation.  This requires us to set this environment up to persist over a period of time (30 periods in this example).\n","\n","We could add additional complexities to the environment as well, such as assets with contingent or deferred payoffs, adversion to risk, taxes, additional data sources, etc.  This is where ML methods can really add value.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8GfW-Cfs68Q2"},"outputs":[],"source":["class InvestmentGame2(gym.Env):\n","    \"\"\"\"\"\"\n","    def __init__(self,risk_free_rate=0, N=100):\n","        \"\"\"\"\"\"\n","        super(InvestmentGame2,self).__init__()\n","        self.action_space = spaces.Box(\n","            low=0,high=1,shape=(5,),dtype=np.float32)\n","        self.observation_space=spaces.Box(\n","            low=-1, high=1, shape=(5+5*100+1,),dtype=np.float32)\n","        self.reward_range=(-3,3)\n","        self.N = N\n","\n","        self.risk_free_rate = risk_free_rate\n","\n","        self.time = 0\n","        self.state_trans_matrix = np.array([[.8,.2]\n","                                           ,[.2,.8]])\n","\n","    def step(self,action):\n","        \"\"\"\"\"\"\n","        self.current_action = action\n","        if action.sum()==0:\n","            self.new_weights = (action+1)/5\n","        else:\n","            self.new_weights = action/action.sum()\n","\n","        self.returns = np.vstack((self.returns[1:,:],self._generate_returns()))\n","\n","        port_returns = self.returns[-1,:]@self.new_weights.reshape(-1,)\n","        change_in_port = np.abs(self.new_weights - self.weights).sum()\n","        cost = 0.01*change_in_port\n","        self.weights = self.new_weights\n","        reward = port_returns - cost\n","        self.time += 1\n","        sharpe = (port_returns.mean()-self.risk_free_rate)/port_returns.std()\n","\n","        if self.time == 30:\n","            terminated = 1\n","        else:\n","            terminated = 0\n","\n","        info = {\"data\":1}\n","        return obs,reward,terminated,0,info\n","\n","    def reset(self,seed=None):\n","        \"\"\"\"\"\"\n","        if not seed is None:\n","            np.random.seed(seed)\n","\n","        self.params = []\n","        self.params.append(generate_market_params(5,self.N))\n","        self.params.append(generate_market_params(5,self.N))\n","        self.state = np.random.choice(2)\n","\n","        for i in range(self.N):\n","            if i == 0:\n","                self.returns = self._generate_returns()\n","            else:\n","                self.returns = np.vstack((self.returns,self._generate_returns()))\n","\n","        self.weights = np.exp(np.random.normal(size=(5,)))\n","        self.weights = self.weights/self.weights.sum()\n","\n","        self.time = 0\n","\n","        obs = self._get_obs()\n","        return obs, {'data':1}\n","\n","    def _get_obs(self):\n","        \"\"\"\"\"\"\n","        obs = np.hstack((self.time/30,self.weights,self.returns.reshape(-1)))\n","        return obs\n","\n","    def _generate_returns(self):\n","        \"\"\"\"\"\"\n","        self.state = np.random.choice(2,p=self.state_trans_matrix[self.state,:])\n","        self.mu,self.Sigma = self.params[self.state]\n","        return generate_market_returns(self.mu,self.Sigma,1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wpLGPMq068Q2","outputId":"b0b96faf-0f80-4fb4-a127-1a38b941828b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cpu device\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\tlhee\\AppData\\Local\\Temp\\ipykernel_18252\\2947046622.py:35: RuntimeWarning: divide by zero encountered in scalar divide\n","  sharpe = (port_returns.mean()-self.risk_free_rate)/port_returns.std()\n"]},{"name":"stdout","output_type":"stream","text":["------------------------------\n","| time/              |       |\n","|    fps             | 571   |\n","|    iterations      | 1     |\n","|    time_elapsed    | 17    |\n","|    total_timesteps | 10000 |\n","------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 521         |\n","|    iterations           | 2           |\n","|    time_elapsed         | 38          |\n","|    total_timesteps      | 20000       |\n","| train/                  |             |\n","|    approx_kl            | 0.048117943 |\n","|    clip_fraction        | 0.0591      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -7.08       |\n","|    explained_variance   | -0.00371    |\n","|    learning_rate        | 0.02        |\n","|    loss                 | -0.00339    |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.00336    |\n","|    std                  | 0.993       |\n","|    value_loss           | 0.00598     |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 512        |\n","|    iterations           | 3          |\n","|    time_elapsed         | 58         |\n","|    total_timesteps      | 30000      |\n","| train/                  |            |\n","|    approx_kl            | 0.05385565 |\n","|    clip_fraction        | 0.061      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -7.08      |\n","|    explained_variance   | 0.0383     |\n","|    learning_rate        | 0.02       |\n","|    loss                 | 0.000178   |\n","|    n_updates            | 20         |\n","|    policy_gradient_loss | -0.00273   |\n","|    std                  | 1          |\n","|    value_loss           | 0.00888    |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 509        |\n","|    iterations           | 4          |\n","|    time_elapsed         | 78         |\n","|    total_timesteps      | 40000      |\n","| train/                  |            |\n","|    approx_kl            | 0.21822175 |\n","|    clip_fraction        | 0.0562     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -7.05      |\n","|    explained_variance   | 0.0494     |\n","|    learning_rate        | 0.02       |\n","|    loss                 | 0.0154     |\n","|    n_updates            | 30         |\n","|    policy_gradient_loss | 0.001      |\n","|    std                  | 0.993      |\n","|    value_loss           | 0.0114     |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 503         |\n","|    iterations           | 5           |\n","|    time_elapsed         | 99          |\n","|    total_timesteps      | 50000       |\n","| train/                  |             |\n","|    approx_kl            | 0.037290625 |\n","|    clip_fraction        | 0.071       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -7.06       |\n","|    explained_variance   | 0.0527      |\n","|    learning_rate        | 0.02        |\n","|    loss                 | 0.00125     |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.000732   |\n","|    std                  | 0.997       |\n","|    value_loss           | 0.0121      |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 505         |\n","|    iterations           | 6           |\n","|    time_elapsed         | 118         |\n","|    total_timesteps      | 60000       |\n","| train/                  |             |\n","|    approx_kl            | 0.022651386 |\n","|    clip_fraction        | 0.0584      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -7.11       |\n","|    explained_variance   | 0.0509      |\n","|    learning_rate        | 0.02        |\n","|    loss                 | -0.00238    |\n","|    n_updates            | 50          |\n","|    policy_gradient_loss | -0.00158    |\n","|    std                  | 1           |\n","|    value_loss           | 0.0127      |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 502         |\n","|    iterations           | 7           |\n","|    time_elapsed         | 139         |\n","|    total_timesteps      | 70000       |\n","| train/                  |             |\n","|    approx_kl            | 0.020785045 |\n","|    clip_fraction        | 0.0531      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -7.08       |\n","|    explained_variance   | 0.0496      |\n","|    learning_rate        | 0.02        |\n","|    loss                 | 0.00597     |\n","|    n_updates            | 60          |\n","|    policy_gradient_loss | -0.00174    |\n","|    std                  | 0.992       |\n","|    value_loss           | 0.0129      |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 506        |\n","|    iterations           | 8          |\n","|    time_elapsed         | 157        |\n","|    total_timesteps      | 80000      |\n","| train/                  |            |\n","|    approx_kl            | 0.01758338 |\n","|    clip_fraction        | 0.0558     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -7.01      |\n","|    explained_variance   | 0.0506     |\n","|    learning_rate        | 0.02       |\n","|    loss                 | 0.00759    |\n","|    n_updates            | 70         |\n","|    policy_gradient_loss | -0.00154   |\n","|    std                  | 0.98       |\n","|    value_loss           | 0.013      |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 505         |\n","|    iterations           | 9           |\n","|    time_elapsed         | 177         |\n","|    total_timesteps      | 90000       |\n","| train/                  |             |\n","|    approx_kl            | 0.015748743 |\n","|    clip_fraction        | 0.0523      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -6.98       |\n","|    explained_variance   | 0.0511      |\n","|    learning_rate        | 0.02        |\n","|    loss                 | 0.00873     |\n","|    n_updates            | 80          |\n","|    policy_gradient_loss | -0.00197    |\n","|    std                  | 0.973       |\n","|    value_loss           | 0.0118      |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 507         |\n","|    iterations           | 10          |\n","|    time_elapsed         | 197         |\n","|    total_timesteps      | 100000      |\n","| train/                  |             |\n","|    approx_kl            | 0.023983091 |\n","|    clip_fraction        | 0.0645      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -6.91       |\n","|    explained_variance   | 0.0522      |\n","|    learning_rate        | 0.02        |\n","|    loss                 | 0.000651    |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.00262    |\n","|    std                  | 0.969       |\n","|    value_loss           | 0.0127      |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 507         |\n","|    iterations           | 11          |\n","|    time_elapsed         | 216         |\n","|    total_timesteps      | 110000      |\n","| train/                  |             |\n","|    approx_kl            | 0.013700006 |\n","|    clip_fraction        | 0.0756      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -6.91       |\n","|    explained_variance   | 0.0526      |\n","|    learning_rate        | 0.02        |\n","|    loss                 | 0.00349     |\n","|    n_updates            | 100         |\n","|    policy_gradient_loss | -0.00391    |\n","|    std                  | 0.962       |\n","|    value_loss           | 0.0119      |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 506         |\n","|    iterations           | 12          |\n","|    time_elapsed         | 237         |\n","|    total_timesteps      | 120000      |\n","| train/                  |             |\n","|    approx_kl            | 0.025313353 |\n","|    clip_fraction        | 0.0693      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -6.89       |\n","|    explained_variance   | 0.0528      |\n","|    learning_rate        | 0.02        |\n","|    loss                 | 0.00275     |\n","|    n_updates            | 110         |\n","|    policy_gradient_loss | -0.00353    |\n","|    std                  | 0.955       |\n","|    value_loss           | 0.0113      |\n","-----------------------------------------\n"]},{"name":"stdout","output_type":"stream","text":["-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 506         |\n","|    iterations           | 13          |\n","|    time_elapsed         | 256         |\n","|    total_timesteps      | 130000      |\n","| train/                  |             |\n","|    approx_kl            | 0.036452822 |\n","|    clip_fraction        | 0.0628      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -6.87       |\n","|    explained_variance   | 0.0518      |\n","|    learning_rate        | 0.02        |\n","|    loss                 | 0.00128     |\n","|    n_updates            | 120         |\n","|    policy_gradient_loss | -0.00245    |\n","|    std                  | 0.945       |\n","|    value_loss           | 0.0106      |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 504         |\n","|    iterations           | 14          |\n","|    time_elapsed         | 277         |\n","|    total_timesteps      | 140000      |\n","| train/                  |             |\n","|    approx_kl            | 0.019853396 |\n","|    clip_fraction        | 0.0445      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -6.79       |\n","|    explained_variance   | 0.0503      |\n","|    learning_rate        | 0.02        |\n","|    loss                 | 0.00391     |\n","|    n_updates            | 130         |\n","|    policy_gradient_loss | -0.000709   |\n","|    std                  | 0.947       |\n","|    value_loss           | 0.0107      |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 505        |\n","|    iterations           | 15         |\n","|    time_elapsed         | 296        |\n","|    total_timesteps      | 150000     |\n","| train/                  |            |\n","|    approx_kl            | 0.03489607 |\n","|    clip_fraction        | 0.0664     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -6.79      |\n","|    explained_variance   | 0.0496     |\n","|    learning_rate        | 0.02       |\n","|    loss                 | 0.00256    |\n","|    n_updates            | 140        |\n","|    policy_gradient_loss | -0.00317   |\n","|    std                  | 0.937      |\n","|    value_loss           | 0.0105     |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 504        |\n","|    iterations           | 16         |\n","|    time_elapsed         | 317        |\n","|    total_timesteps      | 160000     |\n","| train/                  |            |\n","|    approx_kl            | 0.04172864 |\n","|    clip_fraction        | 0.0534     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -6.76      |\n","|    explained_variance   | 0.0504     |\n","|    learning_rate        | 0.02       |\n","|    loss                 | 0.00521    |\n","|    n_updates            | 150        |\n","|    policy_gradient_loss | -0.00145   |\n","|    std                  | 0.936      |\n","|    value_loss           | 0.0101     |\n","----------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 503       |\n","|    iterations           | 17        |\n","|    time_elapsed         | 337       |\n","|    total_timesteps      | 170000    |\n","| train/                  |           |\n","|    approx_kl            | 0.4164199 |\n","|    clip_fraction        | 0.0706    |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -6.72     |\n","|    explained_variance   | 0.0485    |\n","|    learning_rate        | 0.02      |\n","|    loss                 | 0.0132    |\n","|    n_updates            | 160       |\n","|    policy_gradient_loss | -2.22e-05 |\n","|    std                  | 0.927     |\n","|    value_loss           | 0.00996   |\n","---------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 503        |\n","|    iterations           | 18         |\n","|    time_elapsed         | 357        |\n","|    total_timesteps      | 180000     |\n","| train/                  |            |\n","|    approx_kl            | 0.10467917 |\n","|    clip_fraction        | 0.0434     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -6.69      |\n","|    explained_variance   | 0.0521     |\n","|    learning_rate        | 0.02       |\n","|    loss                 | 0.00237    |\n","|    n_updates            | 170        |\n","|    policy_gradient_loss | -0.000989  |\n","|    std                  | 0.925      |\n","|    value_loss           | 0.0093     |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 503         |\n","|    iterations           | 19          |\n","|    time_elapsed         | 377         |\n","|    total_timesteps      | 190000      |\n","| train/                  |             |\n","|    approx_kl            | 0.022809166 |\n","|    clip_fraction        | 0.0593      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -6.67       |\n","|    explained_variance   | 0.0539      |\n","|    learning_rate        | 0.02        |\n","|    loss                 | 0.00539     |\n","|    n_updates            | 180         |\n","|    policy_gradient_loss | -0.00213    |\n","|    std                  | 0.924       |\n","|    value_loss           | 0.00903     |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 501         |\n","|    iterations           | 20          |\n","|    time_elapsed         | 398         |\n","|    total_timesteps      | 200000      |\n","| train/                  |             |\n","|    approx_kl            | 0.010196623 |\n","|    clip_fraction        | 0.0442      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -6.67       |\n","|    explained_variance   | 0.0536      |\n","|    learning_rate        | 0.02        |\n","|    loss                 | 0.00925     |\n","|    n_updates            | 190         |\n","|    policy_gradient_loss | -0.00106    |\n","|    std                  | 0.919       |\n","|    value_loss           | 0.00872     |\n","-----------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 501       |\n","|    iterations           | 21        |\n","|    time_elapsed         | 418       |\n","|    total_timesteps      | 210000    |\n","| train/                  |           |\n","|    approx_kl            | 0.0056823 |\n","|    clip_fraction        | 0.0556    |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -6.64     |\n","|    explained_variance   | 0.0546    |\n","|    learning_rate        | 0.02      |\n","|    loss                 | -0.0002   |\n","|    n_updates            | 200       |\n","|    policy_gradient_loss | -0.00215  |\n","|    std                  | 0.912     |\n","|    value_loss           | 0.00861   |\n","---------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 501          |\n","|    iterations           | 22           |\n","|    time_elapsed         | 438          |\n","|    total_timesteps      | 220000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0063749864 |\n","|    clip_fraction        | 0.0503       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -6.59        |\n","|    explained_variance   | 0.0528       |\n","|    learning_rate        | 0.02         |\n","|    loss                 | 0.00717      |\n","|    n_updates            | 210          |\n","|    policy_gradient_loss | -0.00217     |\n","|    std                  | 0.902        |\n","|    value_loss           | 0.00848      |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 499          |\n","|    iterations           | 23           |\n","|    time_elapsed         | 460          |\n","|    total_timesteps      | 230000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0146284895 |\n","|    clip_fraction        | 0.0587       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -6.51        |\n","|    explained_variance   | 0.0538       |\n","|    learning_rate        | 0.02         |\n","|    loss                 | 0.000857     |\n","|    n_updates            | 220          |\n","|    policy_gradient_loss | -0.00238     |\n","|    std                  | 0.889        |\n","|    value_loss           | 0.00805      |\n","------------------------------------------\n"]},{"name":"stdout","output_type":"stream","text":["------------------------------------------\n","| time/                   |              |\n","|    fps                  | 499          |\n","|    iterations           | 24           |\n","|    time_elapsed         | 480          |\n","|    total_timesteps      | 240000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0065883645 |\n","|    clip_fraction        | 0.0679       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -6.45        |\n","|    explained_variance   | 0.0529       |\n","|    learning_rate        | 0.02         |\n","|    loss                 | 0.00221      |\n","|    n_updates            | 230          |\n","|    policy_gradient_loss | -0.0032      |\n","|    std                  | 0.878        |\n","|    value_loss           | 0.00762      |\n","------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 496         |\n","|    iterations           | 25          |\n","|    time_elapsed         | 503         |\n","|    total_timesteps      | 250000      |\n","| train/                  |             |\n","|    approx_kl            | 0.008223283 |\n","|    clip_fraction        | 0.0475      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -6.36       |\n","|    explained_variance   | 0.0529      |\n","|    learning_rate        | 0.02        |\n","|    loss                 | 0.00177     |\n","|    n_updates            | 240         |\n","|    policy_gradient_loss | -0.0017     |\n","|    std                  | 0.866       |\n","|    value_loss           | 0.00709     |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 496        |\n","|    iterations           | 26         |\n","|    time_elapsed         | 523        |\n","|    total_timesteps      | 260000     |\n","| train/                  |            |\n","|    approx_kl            | 0.01196075 |\n","|    clip_fraction        | 0.0512     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -6.35      |\n","|    explained_variance   | 0.051      |\n","|    learning_rate        | 0.02       |\n","|    loss                 | 0.00871    |\n","|    n_updates            | 250        |\n","|    policy_gradient_loss | -0.00139   |\n","|    std                  | 0.865      |\n","|    value_loss           | 0.0071     |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 496         |\n","|    iterations           | 27          |\n","|    time_elapsed         | 544         |\n","|    total_timesteps      | 270000      |\n","| train/                  |             |\n","|    approx_kl            | 0.007886146 |\n","|    clip_fraction        | 0.0572      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -6.3        |\n","|    explained_variance   | 0.0544      |\n","|    learning_rate        | 0.02        |\n","|    loss                 | 0.000129    |\n","|    n_updates            | 260         |\n","|    policy_gradient_loss | -0.00236    |\n","|    std                  | 0.856       |\n","|    value_loss           | 0.0067      |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 495          |\n","|    iterations           | 28           |\n","|    time_elapsed         | 565          |\n","|    total_timesteps      | 280000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0051317024 |\n","|    clip_fraction        | 0.0422       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -6.3         |\n","|    explained_variance   | 0.0533       |\n","|    learning_rate        | 0.02         |\n","|    loss                 | 0.00259      |\n","|    n_updates            | 270          |\n","|    policy_gradient_loss | -0.001       |\n","|    std                  | 0.851        |\n","|    value_loss           | 0.00614      |\n","------------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 494        |\n","|    iterations           | 29         |\n","|    time_elapsed         | 586        |\n","|    total_timesteps      | 290000     |\n","| train/                  |            |\n","|    approx_kl            | 0.01569077 |\n","|    clip_fraction        | 0.0766     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -6.25      |\n","|    explained_variance   | 0.0514     |\n","|    learning_rate        | 0.02       |\n","|    loss                 | -0.00387   |\n","|    n_updates            | 280        |\n","|    policy_gradient_loss | -0.004     |\n","|    std                  | 0.842      |\n","|    value_loss           | 0.00615    |\n","----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 494          |\n","|    iterations           | 30           |\n","|    time_elapsed         | 607          |\n","|    total_timesteps      | 300000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0110106105 |\n","|    clip_fraction        | 0.0575       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -6.16        |\n","|    explained_variance   | 0.05         |\n","|    learning_rate        | 0.02         |\n","|    loss                 | 0.00107      |\n","|    n_updates            | 290          |\n","|    policy_gradient_loss | -0.00211     |\n","|    std                  | 0.829        |\n","|    value_loss           | 0.006        |\n","------------------------------------------\n"]},{"data":{"text/plain":["<stable_baselines3.ppo.ppo.PPO at 0x225a7255510>"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["env = DummyVecEnv([lambda: InvestmentGame2()])\n","policy_kwargs = dict(activation_fn=th.nn.ReLU,\n","                    net_arch=[dict(pi=[128,64,32],vf=[128,64,32])])\n","model2 = PPO(MlpPolicy, env, learning_rate=0.02, batch_size=1000, gamma=1, n_steps=10000, policy_kwargs=policy_kwargs, verbose=1)\n","obs = env.reset()\n","model2.learn(total_timesteps=300000)"]},{"cell_type":"markdown","metadata":{"id":"R5pYmmeo68Q2"},"source":["### Get used to disappointment\n","In this example, the policy model we learned is still not sufficient to out-perform the traditional optimization approach.  Keep this in mind - machine learning in financial markets is difficult.  There are a few fundamental reasons for this.  First, there is limited data and it is very easy to overfit to limited historical examples.  Second, there are many market participants all looking to get an edge - if an opportunity is discovered, it is quickly exploited and will disappear.  In other words, the data are not stationary - the markets keep adapting based on the behavior of market participants (as well as to changing in policy set by governing bodies)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftn57Yrc68Q2","outputId":"df1a7e27-14a6-4afa-fe5c-d8eae75c9215"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\tlhee\\AppData\\Local\\Temp\\ipykernel_18252\\2051062824.py:35: RuntimeWarning: divide by zero encountered in scalar divide\n","  sharpe = (port_returns.mean()-self.risk_free_rate)/port_returns.std()\n"]},{"data":{"text/plain":["(-7.837197064763865, 2.4560488765826367)"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["policy_tester(InvestmentGame2,model2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oub3CpCz68Q2"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python (port_mgmt)","language":"python","name":"port_mgmt"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[{"file_id":"128wVETzpK9yKgxhgACVa6IOkny1kMa-4","timestamp":1733890419136}]}},"nbformat":4,"nbformat_minor":0}